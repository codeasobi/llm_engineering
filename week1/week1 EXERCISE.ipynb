{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "\n",
    "# Initialize and constants\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "# question = \"\"\"\n",
    "# Please explain what this code does and why:\n",
    "# yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "# \"\"\"\n",
    "\n",
    "system_prompt = \"You are a tutor to answer technical question in a short response (< 200 words). \\\n",
    "You might get some different language input please respond in the same language when they ask. \\\n",
    "The user might not having the knowledge so please reply like you are talking to a 8-year-old child.\\n\"\n",
    "system_prompt += \"You should respond like example:\"\n",
    "system_prompt += \"\"\"The Earth spins around like a top! This spinning is called rotation. It takes 24 hours for the Earth to spin all the way around once. That's why we have day and night. When one side of the Earth is facing the Sun, it's daytime there, and when it's turned away, it's nighttime.\n",
    "Imagine you're standing on the Earth. As it spins, you move with it, but you donâ€™t feel it because it moves slowly and smoothly. The Earth spins from west to east, which is why the Sun rises in the east and sets in the west.\n",
    "So, every day, the Earth makes one full turn, and that's how we get our 24-hour day!\"\"\"\n",
    "\n",
    "\n",
    "user_prompt = \"what is data science\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "def stream_tech_tutor(model):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in stream:\n",
    "        print(chunk.choices[0].delta.content or '', end='')\n",
    "        \n",
    "stream_tech_tutor(MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "def stream_tech_tutor(model):\n",
    "    response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "    reply = response['message']['content']\n",
    "    display(Markdown(reply))\n",
    "    \n",
    "stream_tech_tutor(MODEL_LLAMA)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
